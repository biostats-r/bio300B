<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Linear Regression 1</title>
    <meta charset="utf-8" />
    <meta name="author" content="Richard J. Telford (Richard.Telford@uib.no)" />
    <meta name="date" content="2021-10-12" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <script src="libs/fabric-4.3.1/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Linear Regression 1
## Bio300B Lecture 6
### Richard J. Telford (<a href="mailto:Richard.Telford@uib.no" class="email">Richard.Telford@uib.no</a>)
### Institutt for biovitenskap, UiB
### 12 October 2021

---

&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 24px;
    padding: 1em 4em 1em 4em;
}
&lt;/style&gt;









# Bivariate descriptive statistics

.pull-left[
Measures of association
  - covariance
  - correlation
]
.pull-right[
Use with
- two continuous variables
- paired data
- unclear direction of causality
]
![](lecture_6_linear_regression1_files/figure-html/corr-1.png)&lt;!-- --&gt;

---
## Covariance

.pull-left[
Association between two variables

`\(S_{xy} = \frac{\Sigma (x_i - \mu_x)(y_i - \mu_y)}{n - 1}\)`

`\(S_{xy} = S_{yx}\)`

- \-inf, 0, +inf
- \+ = positive association
- \- = negative association
- `cov()`
]

.pull-right[
![](lecture_6_linear_regression1_files/figure-html/corr-1.png)


]

---
## Correlation

.pull-left[Pearson coefficient of correlation

Standardised association

- `\(S_{xy}\)` - covariance of x &amp; y
- `\(S_x^2\)` - variance of x
- `\(S_y^2\)` - variance of y

`\(r_{xy} = \frac{S_{xy}}{\sqrt{S_x^2S_y^2}}\)`

- \-1, 0, +1
- \+ = positive association
- \- = negative association

`\(r_{xy} = r_{yx}\)`
]
.pull-right[
![](lecture_6_linear_regression1_files/figure-html/corr-1.png)


]

---
## Correlations in R


```r
cor(penguins$bill_length_mm,
    penguins$body_mass_g, 
    use = "pairwise.complete")
```

```
## [1] 0.5951
```


```r
penguins |&gt; 
  select(bill_length_mm:body_mass_g) |&gt; 
cor(use = "complete.obs")
```

```
##                   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## bill_length_mm            1.0000       -0.2351            0.6562      0.5951
## bill_depth_mm            -0.2351        1.0000           -0.5839     -0.4719
## flipper_length_mm         0.6562       -0.5839            1.0000      0.8712
## body_mass_g               0.5951       -0.4719            0.8712      1.0000
```

---
## `\(R^2\)`

Coefficient of determination 

`$$R^2 = r^2$$`

- 0 - 1
- `\(R^2\)` = 0.5, 50% of variation in data explained
---
## Testing a Correlation


```r
cor.test(penguins$bill_length_mm,
    penguins$body_mass_g, 
    use = "pairwise.complete")
```

```
## 
## 	Pearson's product-moment correlation
## 
## data:  penguins$bill_length_mm and penguins$body_mass_g
## t = 14, df = 340, p-value &lt;2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.5220 0.6595
## sample estimates:
##    cor 
## 0.5951
```

Not robust to outliers

 - Non-parametric correlation (Spearman Rank, Kendall Tau)
 - Bootstrap estimation of confidence interval

---
# Least squares regression

- Describe relationship between response _y_ and predictor _x_
`$$y = β_0 + β_1x$$`
- Estimate model coefficients with uncertainty
- Test if terms in the model are significant
- Check the method's assumptions
- View the model diagnostics
- Make predictions with confidence intervals

![](lecture_6_linear_regression1_files/figure-html/lin-mods-1.png)&lt;!-- --&gt;


---
# We want the parameters `\(\beta\)`

$$y_i = \beta_0 + \beta_1x_i + \epsilon_i  $$

- `\(y\)` = continuous response
- `\(x\)` = continuous or categorical predictor
- `\(i = 1, ..., n\)` observations
- `\((xi, yi)\)` observation pairs
- `\(ε_i\)` = residual at `\(i\)`
- `\(β_0\)` = mean, intercept
- `\(β_1\)` = effect, slope

Residuals are actual - predicted

Criteria

- `\(\epsilon \sim N(0, \sigma)\)` 
- `\(y \sim N(\mu, \sigma)\)`

---

Use when

- Response variable is continuous
- Predictor variable(s) are continuous or categorical
- Observations are independent

+ Other assumptions are met

- Direction of causality is clear
- Want to make predictions
- Want effect size as slope or differences between groups


---
# Correlation or linear model

Study to find relationship between foraminifera test composition and temperature

1) Experiment to with individual forams in tanks at different temperatures.

- Variables test Mg concentration, tank temperature
- Variables Test Mg concentration, test Ba concentration 

2) Observational study of forams collected from the ocean.

- Variables test Mg concentration, Ocean temperature
- Variables Ocean temperature, ocean Mg concentration
- Variables test Mg concentration, foram species

---
# Estimating `\(\beta\)`

.pull_left[
Choose `\(\beta\)` that minimise the sum of squares of residuals

`$$\sum_{i = 1}^{n}\epsilon_i^2 =   \sum_{i = 1}^{n}(y_i - (\beta_0 + \beta_1x_i))^2$$`

]

.pull_right[
![](lecture_6_linear_regression1_files/figure-html/slope-anim-1.gif)&lt;!-- --&gt;
]

---
## Calculating `\(\beta\)`


`$$\beta_1 = \frac{s_{xy}}{s_x^2}$$`
 Covariance of xy / variance of x
 
`$$\beta_0 = mean(y) - \beta_1 mean(x)$$`


---
# Fitting a least-squares model in R


```r
gentoo &lt;- penguins |&gt; filter(species == "Gentoo")

mod &lt;- lm(bill_length_mm ~ body_mass_g, data = gentoo)
mod
```

```
## 
## Call:
## lm(formula = bill_length_mm ~ body_mass_g, data = gentoo)
## 
## Coefficients:
## (Intercept)  body_mass_g  
##    26.73955      0.00409
```

---
## Summary


```r
summary(mod)
```

```
## 
## Call:
## lm(formula = bill_length_mm ~ body_mass_g, data = gentoo)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -5.880 -1.508 -0.058  1.312  8.111 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2.67e+01   2.11e+00   12.69   &lt;2e-16 ***
## body_mass_g 4.09e-03   4.13e-04    9.91   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.3 on 121 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.448,	Adjusted R-squared:  0.443 
## F-statistic: 98.1 on 1 and 121 DF,  p-value: &lt;2e-16
```


---
# Variance partitioning


.pull-left[

**Total sum of squares** `\(SS_{total}\)`

Squared differences of observation from mean

**Residual sum of squares** `\(SS_{residual}\)`

Squared differences of observation from regression line

**Regression sum of squares** `\(SS_{regression}\)`

Squared differences of regression line from mean
]
.pull-right[
![](lecture_6_linear_regression1_files/figure-html/ss-plot-1.png)&lt;!-- --&gt;
]

---
# `\(R^2\)`


Coefficient of determination 

Coefficient of multiple correlation

  `$$R^2 = 1 - \frac{SS_{residual}}{SS_{total}}$$`
 
 - 0 - 1
 - `\(R^2\)` = 0.5  -- 50% of variation in data explained
 - Always increases with more predictors
 
 - Adjusted `\(R^2\)` corrects for number of parameters
 - Can be negative
 
---
## Anova

`$$F = \frac{SS_{regression}/df_{regression}}{SS_{residual}/df_{residual}}$$`


```r
car::Anova(mod)
```

```
## Anova Table (Type II tests)
## 
## Response: bill_length_mm
##             Sum Sq  Df F value Pr(&gt;F)    
## body_mass_g    519   1    98.1 &lt;2e-16 ***
## Residuals      640 121                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
# The F distribution


![](lecture_6_linear_regression1_files/figure-html/F-1.png)&lt;!-- --&gt;

---
# Categorical predictors

Does penguin body mass depend on species?

Predictor = species (categorical)

Response = body mass (continuous)

Hypotheses 

`$$H_0: \mu_{Adelie} = \mu{Chinstrap} = \mu{Gentoo}$$`
`\(H_A\)` At least two of the means differ

---

```r
ggplot(penguins, aes(x = species, y = body_mass_g, fill = species)) +
  geom_violin(show.legend = FALSE) +
  scale_fill_brewer(palette = "Set1")
```

![](lecture_6_linear_regression1_files/figure-html/species-plot-1.png)&lt;!-- --&gt;

---
## Fitting the model


```r
mod2 &lt;- lm(body_mass_g ~ species, data = penguins)
mod2
```

```
## 
## Call:
## lm(formula = body_mass_g ~ species, data = penguins)
## 
## Coefficients:
##      (Intercept)  speciesChinstrap     speciesGentoo  
##           3700.7              32.4            1375.4
```

---
## Anova


```r
car::Anova(mod2)
```

```
## Anova Table (Type II tests)
## 
## Response: body_mass_g
##             Sum Sq  Df F value Pr(&gt;F)    
## species   1.47e+08   2     344 &lt;2e-16 ***
## Residuals 7.24e+07 339                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

At least two groups differ

---
## Summary


```r
summary(mod2)
```

```
## 
## Call:
## lm(formula = body_mass_g ~ species, data = penguins)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1126.0  -333.1   -33.1   316.9  1224.0 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        3700.7       37.6   98.37   &lt;2e-16 ***
## speciesChinstrap     32.4       67.5    0.48     0.63    
## speciesGentoo      1375.4       56.1   24.50   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 462 on 339 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.67,	Adjusted R-squared:  0.668 
## F-statistic:  344 on 2 and 339 DF,  p-value: &lt;2e-16
```

---
Summary shows difference between 

- Adelie and Chinstrap
- Adelie and Gentoo

Not between 

 - Chinstrap and Adelie

---
## Forcing the reference level

Very useful when you have a control


```r
penguins2 &lt;- penguins |&gt; 
  mutate(species = factor(species, levels = c("Gentoo", "Adelie", "Chinstrap")))

mod3 &lt;- lm(body_mass_g ~ species, data = penguins2)
```

---

```r
broom::tidy(mod3)
```

```
## # A tibble: 3 × 5
##   term             estimate std.error statistic   p.value
##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)         5076.      41.7     122.  6.86e-282
## 2 speciesAdelie      -1375.      56.1     -24.5 5.42e- 77
## 3 speciesChinstrap   -1343.      69.9     -19.2 3.21e- 56
```

---
# Multiple comparisons

Instead of changing the order of the levels of the predictor variable to 
compare all groups against each other, use a post-hoc multiple comparisons test


```r
#multcomp package is badly behaved - it loads plyr package which has lots of conflicts with dplyr
# Solution - use conflicted package or multcomp::glht

mc &lt;- multcomp::glht(mod2, linfct = multcomp::mcp(species="Tukey"),
           data = penguins)
summary(mc)
```

---

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = body_mass_g ~ species, data = penguins)
## 
## Linear Hypotheses:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## Chinstrap - Adelie == 0     32.4       67.5    0.48     0.88    
## Gentoo - Adelie == 0      1375.4       56.1   24.50   &lt;1e-05 ***
## Gentoo - Chinstrap == 0   1342.9       69.9   19.22   &lt;1e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
```

---

```r
plot(mc)
```

![](lecture_6_linear_regression1_files/figure-html/multicomp-1.png)&lt;!-- --&gt;


---
# Assumtions of Least Squares

1. The relationship between the response and the predictors is ~linear.
2. The residuals have a mean of zero.
3. The residuals have constant variance (not heteroscedastic).
4. The residuals are independent (uncorrelated).
5. The residuals are normally distributed.

Violation of assumptions cannot be detected using the t or F statistics or R&lt;sup&gt;2&lt;/sup&gt;

---
# Diagnostic plots


```r
library(ggfortify)
autoplot(mod) # can also use plot(mod)
```

![](lecture_6_linear_regression1_files/figure-html/all-diagnostics-1.png)&lt;!-- --&gt;


---
## Residual vs fitted

.pull-left[
Check for

- Outliers
- Variations in the mean residual

Want flat line
]

.pull-right[

```r
autoplot(mod, which = 1)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-1-1.png)&lt;!-- --&gt;
]

---
## Quantile-quantile plot

.pull-left[
QQ plots compare two
samples to determine if they are from the same distribution.


Check for

- Non-normal distribution of the residuals

Points will lie on straight line if normally distributed
]

.pull-right[


```r
autoplot(mod, which = 2)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-2-1.png)&lt;!-- --&gt;
]

---
## Scale-location plot

.pull-left[
Square root of the absolute standardised residuals 

Check for

- Unequal variance
= Heteroscedasticity

Want flat line
]

.pull-right[


```r
autoplot(mod, which = 3)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-3-1.png)&lt;!-- --&gt;
]

---
## Cook's distance

.pull-left[
Influence of individual points on the fitted values

– how much do fitted values change when observation _i_ removed

Points with a D &gt; 4/n merit examination
]

.pull-right[


```r
autoplot(mod, which = 4)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-4-1.png)&lt;!-- --&gt;
]

---
## Residuals vs leverage

.pull-left[
Plot of standardised residuals against leverage, with contours of Cooks distance

Observations with extreme leverage should be checked]

.pull-right[


```r
autoplot(mod, which = 5)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-5-1.png)&lt;!-- --&gt;
]

---
## Cook's distance vs leverage

.pull-left[
Influence vs leverage with contours of standardised residuals

Check extreme observations
]

.pull-right[


```r
autoplot(mod, which = 6)
```

![](lecture_6_linear_regression1_files/figure-html/diagnostic-6-1.png)&lt;!-- --&gt;
]

---
# Predictions

.pull-left[
`$$y = \beta_0+\beta_1x$$`


```r
coef(mod)
```

```
## (Intercept) body_mass_g 
##   26.739548    0.004091
```

```r
x &lt;- 5000
coef(mod)[1] +coef(mod)[2] * x
```

```
## (Intercept) 
##       47.19
```
]

.pull-right[

![](lecture_6_linear_regression1_files/figure-html/pred-plot-1.png)&lt;!-- --&gt;
]

---
## Predict


```r
predict(object = mod)
```

```
##     1     2     3     4     5     6     7     8     9    10    11    12    13 
## 45.15 50.06 44.94 50.06 48.83 45.35 46.38 48.01 44.74 47.81 45.76 49.44 45.76 
##    14    15    16    17    18    19    20    21    22    23    24    25    26 
## 50.67 43.92 50.67 43.72 52.51 46.38 48.63 50.06 47.19 44.74 47.40 47.19 47.60 
##    27    28    29    30    31    32    33    34    35    36    37    38    39 
## 43.51 49.85 45.56 49.44 48.22 45.97 47.40 51.49 47.81 48.83 46.99 48.22 44.53 
##    40    41    42    43    44    45    46    47    48    49    50    51    52 
## 48.63 42.90 50.06 44.33 46.17 49.44 46.78 43.92 48.83 47.60 48.42 46.58 48.42 
##    53    54    55    56    57    58    59    60    61    62    63    64    65 
## 44.74 47.19 46.78 47.40 44.33 47.19 44.94 49.44 43.92 48.42 44.74 49.85 45.97 
##    66    67    68    69    70    71    72    73    74    75    76    77    78 
## 50.06 45.76 50.47 45.97 49.44 46.17 47.19 47.60 48.01 45.97 50.47 45.56 51.28 
##    79    80    81    82    83    84    85    86    87    88    89    90    91 
## 46.17 51.08 45.66 49.03 46.07 48.63 46.17 49.65 45.56 48.42 46.68 49.44 46.99 
##    92    93    94    95    96    97    98    99   100   101   102   103   104 
## 48.83 46.17 49.85 46.58 48.01 46.89 46.68 45.66 48.22 46.58 49.65 47.09 49.24 
##   105   106   107   108   109   110   111   112   113   114   115   116   117 
## 46.07 49.24 45.97 49.24 45.46 49.24 47.19 51.08 45.76 49.24 44.64 50.67 46.68 
##   118   119   121   122   123   124 
## 51.28 46.89 46.58 50.26 48.01 48.83
```

---
## Predict with new data


```r
nd &lt;- tibble(body_mass_g = c(5000, 7000))
predict(mod, newdata = nd)
```

```
##     1     2 
## 47.19 55.38
```

---
## Predictions with standard errors

Uncertainty of the mean


```r
predict(mod, newdata = nd, se.fit = TRUE)
```

```
## $fit
##     1     2 
## 47.19 55.38 
## 
## $se.fit
##      1      2 
## 0.2097 0.8212 
## 
## $df
## [1] 121
## 
## $residual.scale
## [1] 2.3
```

---
## Predictions with confidence interval


```r
predict(mod, newdata = nd, interval = "confidence", level = 0.95)
```

```
##     fit   lwr   upr
## 1 47.19 46.78 47.61
## 2 55.38 53.75 57.00
```

---

Often easier to use `broom::augment()`


```r
augment(mod, interval = "confidence") |&gt; 
  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +
  geom_point() +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .3)+
  geom_line(aes(y = .fitted))
```

![](lecture_6_linear_regression1_files/figure-html/augment-1.png)&lt;!-- --&gt;


---
## Predictions interval

Where will a new observation probably be



```r
augment(mod, interval = "prediction") |&gt; 
  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +
  geom_point() +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = .3)+
  geom_line(aes(y = .fitted))
```

![](lecture_6_linear_regression1_files/figure-html/prediction-interval-1.png)&lt;!-- --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
